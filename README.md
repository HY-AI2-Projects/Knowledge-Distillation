# Knowledge-Distillation
AI2 ê¸°ë§ í”„ë¡œì íŠ¸_ì •ë³´ìœµí•©ì „ê³µ 2020017210 ë°°ìœ ê²½

NIPS 2014 workshopì—ì„œ ë°œí‘œí•œ "Distilling the Knowledge in a Neural Network"ë…¼ë¬¸ê³¼ ë…¼ë¬¸êµ¬í˜„ ì½”ë“œì— ëŒ€í•´ ì†Œê°œí•˜ê² ìŠµë‹ˆë‹¤.

## Knowledge Distillationì˜ ë“±ì¥ë°°ê²½
ë”¥ëŸ¬ë‹ì˜ ë°œì „ìœ¼ë¡œ ëª¨ë¸ì€ ì ì  ë” ê¹Šì–´ì§€ê³  í¬ê¸°ê°€ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ì—¬ëŸ¬ ë¬¸ì œì ì´ ë°œìƒí•©ë‹ˆë‹¤.

**1) ëª¨ë¸ë°°í¬ ë¬¸ì œ**

**2) ë¹„ìš©, ì¶”ë¡ ì‹œê°„ ì¦ê°€ ë¬¸ì œ**

**3) ì‹¤ìš©ì  ì¸¡ë©´ì—ì„œì˜ ë¬¸ì œ**

ë³µì¡í•œ êµ¬ì¡°ë¥¼ ê°€ì§„ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì—¬ëŸ¬ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ í•©ì³ì„œ í™œìš©í•˜ëŠ” ì•™ìƒë¸” ê¸°ë²•ì´ ëŒ€í‘œì ìœ¼ë¡œ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì•„ë¬´ë¦¬ ë³µì¡í•œ ëª¨ë¸ì¼ì§€ë¼ë„ ìµœê³ ì˜ ì •í™•ë„ë¥¼ ë‚´ë„ë¡ ì„¤ê³„ë˜ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ëª¨ë¸ì€ ì‹¤ì œ ì‚¬ìš©ìì—ê²Œ ì í•©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë°”ì¼ì´ë‚˜ ìë™ì°¨ì™€ ê°™ì´ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” í™˜ê²½ì—ì„œëŠ” ì´ëŸ° ë³µì¡í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ë˜ ì•™ìƒë¸” ê¸°ë²•ì„ í†µí•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ë†’ì•„ì§ˆ ìˆ˜ ìˆê² ì§€ë§Œ, ëŒ€ê·œëª¨ ëª¨ë¸ì€ ì—¬ëŸ¬ ëª¨ë¸ì´ í•©ì³ì§„ ë§Œí¼ ë¹„ìš©ì´ ê³¼ë„í•˜ê²Œ ë“¤ì–´ê°€ê³ , ê°™ì€ ìì›ì´ë¼ë©´ ì¶”ë¡ ì‹œê°„ì´ ì¦ê°€ í•  ìˆ˜ ë°–ì— ì—†ìŠµë‹ˆë‹¤. ê·¸ë ‡ê¸°ë•Œë¬¸ì— ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜í–‰ë˜ì–´ì•¼í•˜ëŠ” ì‘ì—…ì— ìˆì–´ì„œëŠ” ì ìš©ë˜ê¸°ê°€ í˜ë“­ë‹ˆë‹¤. ì´ì—ë”°ë¼ **ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ë” ë¹ ë¥´ê³  ê°€ë³ê²Œ í•  í•„ìš”ì„±ì„ ê°€ì§€ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.** ì´ë•Œ ë“±ì¥í•œ ê°œë…ì´ Knowledge Distillation ì…ë‹ˆë‹¤. 

## Knowledge Distillation ì´ë€?
í•œêµ­ì–´ë¡œ **'ì§€ì‹ ì¦ë¥˜'** ë¼ê³  í•˜ëŠ”ë°ìš”. ì¦ë¥˜ëŠ” ë¶ˆìˆœë¬¼ì´ ì„ì—¬ìˆëŠ” í˜¼í•©ë¬¼ì— ì˜¨ë„ë¥¼ ê°€í•˜ì—¬ ì›í•˜ëŠ” ì„±ë¶„ì„ ë¶„ë¦¬ì‹œí‚¤ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì´ê²ƒì„ ë”¥ëŸ¬ë‹ì— ì ìš©ì‹œí‚¤ë©´ **"ë¶ˆí•„ìš”í•˜ê²Œ ë§ì€ íŒŒë¼ë¯¸í„°ê°€ ì‚¬ìš©ë˜ëŠ” ê¸°ì¡´ì˜ ë³µì¡í•œ ëª¨ë¸ë“¤ë¡œë¶€í„°, ë³´ë‹¤ ë‹¨ìˆœí™”ëœ ëª¨ë¸ì— ì§€ì‹ì„ ì „ë‹¬í•´ì„œ í•µì‹¬ ë¶€ë¶„ì€ ì‚´ë¦¬ê³ , ë¶ˆí•„ìš”í•œ ë¶€ë¶„ì€ ì œê±°í•˜ì—¬ ëª¨ë¸ì†ë„ë¥¼ ê°œì„ í•˜ëŠ” ê²ƒ"** ì…ë‹ˆë‹¤.

Knowledge Distillation ì—ëŠ” Teacher Modelê³¼ Student Modelì´ í•„ìš”í•©ë‹ˆë‹¤.
> Teacher Model (ì„ ìƒëª¨ë¸) : ë†’ì€ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ê°€ì§„ ë³µì¡í•œ ëª¨ë¸

 
> Student Model (í•™ìƒëª¨ë¸) : ì„ ìƒëª¨ë¸ì˜ ì§€ì‹ì„ ë°›ëŠ” ì–•ê³  ë‹¨ìˆœí•œ ëª¨ë¸

ì„ ìƒë‹˜ì´ í•™ìƒì—ê²Œ ê°€ë¥´ì¹¨ì„ í†µí•´ ì§€ì‹ì„ ì£¼ëŠ” ê²ƒ ì²˜ëŸ¼ **ì˜ í•™ìŠµëœ Teacher Modelì˜ ì§€ì‹ì„ Student Modelì—ê²Œ ì „ë‹¬í•˜ì—¬ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë‚´ê³ ì í•˜ëŠ” ê²ƒì´ Knowledge Distillaionì˜ ëª©ì ì…ë‹ˆë‹¤.**

![ìŠ¤í¬ë¦°ìƒ· 2023-12-13 001529](https://github.com/bae60/AI/assets/146174793/2d23749e-8045-4277-82b6-04f278b26baf) 

ìœ„ì˜ ì˜ˆì‹œì²˜ëŸ¼ ì •í™•ë„ 95%, ì¶”ë¡ ì‹œê°„ 2ì‹œê°„ì¸ Teacher Modelì´ ìˆë‹¤ê³  ê°€ì •í•´ë³´ê² ìŠµë‹ˆë‹¤. ì´ ì˜ í•™ìŠµì‹œí‚¨ Teacher Modelì˜ ì§€ì‹ì„ ë‹¨ìˆœí•œ Student Modelì—ê²Œ ì „ë‹¬í•˜ì—¬ ì •í™•ë„ 90%, ì¶”ë¡ ì‹œê°„ 5ë¶„ì˜ ì„±ëŠ¥ì„ ë‚´ë„ë¡ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

## Knowledge Distillaion ì ìš© ê³¼ì •
![image](https://github.com/bae60/AI/assets/146174793/f5d80690-9871-49c8-95f5-aa2707189f89)

**1) Soft Target**

![2ì œëª© ì—†ìŒ](https://github.com/bae60/AI/assets/146174793/4d47b99f-3873-4455-8fe9-a1c3ee8818f4)

ì¼ë°˜ì ì¸ ë¶„ë¥˜ëª¨ë¸ì—ì„œëŠ” ì…ë ¥ê°’ì´ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µê³¼í•˜ë©´ ë§ˆì§€ë§‰ì— ë¡œì§“ê°’ì´ ì‚°ì¶œë˜ê²Œ ë©ë‹ˆë‹¤. ì—¬ê¸°ì— softmaxë¥¼ ì·¨í•˜ì—¬ í•©ì´ 1ì¸ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í˜•í•©ë‹ˆë‹¤. ê°€ì¥ ë†’ì€ í™•ë¥ ê°’ì„ ë³´ì´ëŠ” í´ë˜ìŠ¤ì—ëŠ” 1ì„ ë¶€ì—¬í•˜ê³  ë‚˜ë¨¸ì§€ì˜ í´ë˜ìŠ¤ì— ëŒ€í•´ì„œëŠ” 0ì„ ë¶€ì—¬í•˜ì—¬ ì•„ì›ƒí’‹ì„ ë„ì¶œí•˜ëŠ” One-hot ì¸ì½”ë”© ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” **1ê³¼ 0ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì§„ ì˜ˆì¸¡ê°’ì„ Hard Target** ì´ë¼ê³  ì´ë¦„ ë¶™í˜”ìŠµë‹ˆë‹¤. Knowledge Distillaionì€ Hard Targetì´ ì•„ë‹Œ Soft Targetì„ ì‚¬ìš©í•˜ê³  ìˆëŠ”ë°ìš”.

![3ì œëª© ì—†ìŒ](https://github.com/bae60/AI/assets/146174793/170d806e-fdd1-4604-b87b-e6760e0ef40c)

**Soft Target ì€ One-hot ì¸ì½”ë”©ì„ ê±°ì¹˜ì§€ ì•Šì€ ì˜ˆì¸¡ê²°ê³¼ì˜ í™•ë¥ ë¶„í¬ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.** ìœ„ì˜ Soft Targetì„ ë³´ë©´ ì…ë ¥ì´ë¯¸ì§€ê°€ í† ë¼ë³´ë‹¤ëŠ” ê³ ì–‘ì´ì— ê°€ê¹ê³  ê³ ì–‘ì´ë³´ë‹¤ëŠ” ê°•ì•„ì§€ì— ë” ê°€ê¹ë‹¤ëŠ” ê²ƒ, ê³ ì–‘ì´ì™€ ê°•ì•„ì§€ê°€ ì–´ëŠì •ë„ ë¹„ìŠ·í•œ íŠ¹ì§•ì´ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ° ì ì—ì„œ ë´¤ì„ ë•Œ, ê¸°ì¡´ì˜ ì •ë‹µë°ì´í„°ì¸ Hard Targetë³´ë‹¤ Soft Targetì´ ê°–ëŠ” ì •ë³´ê°€ ë” í¬ë¯€ë¡œ ì´ ì§€ì‹ì„ Student Modelì—ê²Œ ì „ë‹¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì´ë ‡ê²Œ Soft Targetì„ í†µí•´ ì •ë³´ì†ì‹¤ì„ ìµœì†Œí™”í–ˆì§€ë§Œ ê°€ì¥ í° ë¡œì§“ê°’ì„ ê°–ëŠ” ë…¸ë“œì˜ ì¶œë ¥ê°’ì€ 1ê³¼ ë§¤ìš° ê°€ê¹Œìš´ ê°’ì„ ê°€ì§€ê³ , ë‚˜ë¨¸ì§€ëŠ” 0ì— ê°€ê¹Œìš´ ê°’ìœ¼ë¡œ ë§¤í•‘ë˜ëŠ” ë¬¸ì œì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë¬¸ì œì ì„ ê°œì„ í•˜ê¸° ìœ„í•´ **ğ‰(temperature)** ë¼ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ Softmax í•¨ìˆ˜ì— ì¶”ê°€í•˜ì—¬ ì•½ê°„ì˜ ë³€í˜•ì„ ì·¨í•´ì¤ë‹ˆë‹¤. ğ‰ëŠ” ì¼ì¢…ì˜ Scaling ì—­í• ì„ í•©ë‹ˆë‹¤. 
![4ì œëª© ì—†ìŒ](https://github.com/bae60/AI/assets/146174793/aa94c93f-155a-4155-81ac-e5d59b70c918)

**2) ì†ì‹¤í•¨ìˆ˜**

![image](https://github.com/bae60/AI/assets/146174793/d8f12b77-9752-48c1-aed7-25f68165dd10)
ğ‘† = Student model , ğ‘‡ = Teacher model 


ì•ì— ìˆ˜ì‹ì€ Distillaion lossë¥¼ êµ¬í•©ë‹ˆë‹¤. Sê°€ êµ¬í•œ soft prediction, Tê°€ êµ¬í•œ soft labelì˜ ì°¨ì´ë¡œ ì†ì‹¤ì„ êµ¬í•©ë‹ˆë‹¤. 
ë’¤ì— ìˆ˜ì‹ì€ ì¼ë°˜ì ì¸ ì‹ ê²½ë§ í•™ìŠµì— ì‚¬ìš©í•˜ëŠ” ì†ì‹¤ì…ë‹ˆë‹¤. Sê°€ êµ¬í•œ soft predictionê³¼ ì›ë˜ ë°ì´í„°ê°€ ê°€ì§€ê³  ìˆëŠ” hard labelì˜ ì°¨ì´ë¡œ ì†ì‹¤ì„ êµ¬í•©ë‹ˆë‹¤. 
ì´ ë‘ê°€ì§€ ì†ì‹¤ì˜ í•©ì„ ìµœì¢… ì†ì‹¤ë¡œ ì‚¼ì•„ í•™ìŠµí•©ë‹ˆë‹¤.

## Knowledge Distillation ë…¼ë¬¸êµ¬í˜„
ë³¸ ì½”ë“œëŠ” https://github.com/Seonghoon-Yu/AI_Paper_Review/blob/master/Classification/Knowledge_distillation(2014).ipynb ì˜ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤.

#### ìš°ì„  í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ import í•©ë‹ˆë‹¤.
```
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import torchvision.models as models
from torch.utils.data import DataLoader
import time
import os
import copy
from torchvision.transforms.functional import to_pil_image
import matplotlib.pyplot as plt
%matplotlib inline

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```

#### Loading MNIST dataset
MNINST datasetì„ ë¶ˆëŸ¬ì˜¤ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.
```
# make directorch to save dataset
def createFolder(directory):
    try:
        if not os.path.exists(directory):
            os.makedirs(directory)
    except OSerror:
        print('Error')
createFolder('./data')
```
```
# define transformation
ds_transform = transforms.Compose([
                        transforms.ToTensor(),
                        transforms.Normalize((0.1307,),(0.3081,))
])
```

datasetì„ ìƒì„±í•©ë‹ˆë‹¤.
```
# load MNIST dataset
train_ds = datasets.MNIST('/content/data',train=True, download=True, transform=ds_transform)
val_ds = datasets.MNIST('/content/data',train=False, download=True, transform=ds_transform)
```

ë°ì´ë” ë¡œë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
```
# define data loader
train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)
val_dl = DataLoader(val_ds, batch_size = 128, shuffle=True)
```

ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
```
# check sample image
for x, y in train_dl:
    print(x.shape, y.shape)
    break

num = 4
img = x[:num]

plt.figure(figsize=(15,15))
for i in range(num):
    plt.subplot(1,num+1,i+1)
    plt.imshow(to_pil_image(0.1307*img[i]+0.3081), cmap='gray')
```



